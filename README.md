# SignX: Gestural Audio Interface

## 1. Mission Brief
SignX is a computer vision system designed to bridge the gap between sign language and vocal communication. It utilizes **MediaPipe** for skeletal tracking and a **K-Nearest Neighbors (KNN)** algorithm for one-shot classification. The system translates hand gestures into synthesized audio in real-time.



## 2. Intelligence Package (File Structure)

This directory contains the necessary components for the model's lifecycle, from raw data to real-time execution.
```
 .
├── 󱧼 build
│   └──  model.p
├──  data
│   ├──  0.npy
│   ├──  1.npy
│   ├──  2.npy
│   ├──  3.npy
│   ├──  4.npy
│   ├──  5.npy
│   ├──  6.npy
│   ├──  7.npy
│   ├──  8.npy
│   ├──  9.npy
│   └──  10.npy
├──  flake.lock
├──  flake.nix
├──  init.py
├──  project.toml
├── 󰂺 README.md
└── 󰣞 src
    ├──  test.py
    └──  train.py
```

### **Core Assets**
* **`data/*.npy` (0.npy - 10.npy)**
    * **Classification:** Raw Intelligence.
    * **Purpose:** These files contain the "DNA" of each sign. Each file holds a 126-dimensional vector representing the X, Y, and Z coordinates of both hands (21 points × 3 axes × 2 hands).
    * **Importance:** Critical. Without these, the model has no reference point to learn what a "0" or "1" looks like.
    * **Note:** Currently configured for **One-Shot Learning** (1 example per class).

* **`build/model.p`**
    * **Classification:** Artifact.
    * **Purpose:** The serialized "Brain" of the operation. This is the compiled KNN classifier generated by `train.py`.
    * **Importance:** High. `test.py` loads this file to make predictions. If deleted, it must be regenerated.

### **Operational Scripts**
* **`src/train.py`**
    * **Classification:** Compiler.
    * **Purpose:** The training pipeline. It aggregates the scattered `.npy` files, labels them based on their filenames, and fits the KNN model.
    * **Output:** Generates `build/model.p`.

* **`src/test.py`**
    * **Classification:** Effector (Runtime).
    * **Purpose:** The real-time execution loop. It:
        1. Activates the camera.
        2. Extract hand landmarks using MediaPipe.
        3. Queries the `model.p` for the closest match.
        4. Triggers the Text-to-Speech engine.

### **Environment Configuration**
* **`flake.nix` / `flake.lock`**
    * **Purpose:** Defines the reproducible build environment for NixOS systems. Ensures all system-level dependencies (glibc, libstdc++, opencv) are injected correctly.
* **`project.toml`**
    * **Purpose:** For easy accessibility of files from code by seting the root directory of the project.

---

## 3. Deployment Protocols

```
git clone https://github.com/JithinSunildas.git/signx
cd signx
```

**1. Prerequisites:**
Ensure Python 3.10 or 3.11 is installed.
- Search web for instructions if you use Windows.
- Python is pre-installed in most of the linux distros.
   - Update the version if needed.
   - In most cases it will be latest version.

**2. Install Dependencies and Build:**
```bash
pip install numpy opencv-python mediapipe pyttsx3 scikit-learn
python3 src/train.py
python3 src/test.py
```

--- 
